{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35713d49-4863-4877-87e9-9d9d29096bba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 15:04:39,588\tWARNING deprecation.py:50 -- DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.examples.env.cartpole_mass import CartPoleMassEnv\n",
    "\n",
    "from src.maml import meta_train, meta_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "907a4bfe-0095-4c57-8cbd-343a1e497e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "default_training = {\n",
    "        \"train_batch_size\": 2048,        # environment steps for each inner update\n",
    "        \"lr\": 1e-3,                      # learning rate.\n",
    "        \"inner_adaptation_steps\": 2,     # inner-loop gradient updates\n",
    "        \"maml_optimizer_steps\": 1,     # outer-loop meta-updates\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b480f42e-c44d-431c-a677-59b42ea2dbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfd8e070-1d52-49e0-b480-69a3755bda01",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-03-04 14:45:11</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:09.30        </td></tr>\n",
       "<tr><td>Memory:      </td><td>31.8/47.1 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 4.0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CustomMetaEnv-v0_1d2ea_00000</td><td>TERMINATED</td><td>10.150.0.3:3730988</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         56.3283</td><td style=\"text-align: right;\">10240</td><td style=\"text-align: right;\">   84.29</td><td style=\"text-align: right;\">                 402</td><td style=\"text-align: right;\">                  12</td><td style=\"text-align: right;\">             84.29</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 14:44:02,170\tWARNING algorithm_config.py:2558 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "\u001b[2m\u001b[36m(pid=3730988)\u001b[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=3730988)\u001b[0m 2025-03-04 14:44:06,175\tWARNING algorithm_config.py:2558 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "\u001b[2m\u001b[36m(PPO pid=3730988)\u001b[0m 2025-03-04 14:44:06,176\tWARNING algorithm_config.py:656 -- Cannot create PPOConfig from given `config_dict`! Property maml_checkpoint_path not supported.\n",
      "\u001b[2m\u001b[36m(PPO pid=3730988)\u001b[0m 2025-03-04 14:44:10,068\tWARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=3730988)\u001b[0m 2025-03-04 14:44:10,068\tWARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=3730988)\u001b[0m 2025-03-04 14:44:10,068\tWARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=3730988)\u001b[0m 2025-03-04 14:44:10,068\tWARNING deprecation.py:50 -- DeprecationWarning: `KLCoeffMixin` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3731081)\u001b[0m 2025-03-04 14:44:10,027\tWARNING env.py:162 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(pid=3731135)\u001b[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3731081)\u001b[0m 2025-03-04 14:44:10,030\tWARNING algorithm_config.py:2558 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(PPO pid=3730988)\u001b[0m Install gputil for GPU system monitoring.\n",
      "2025-03-04 14:45:11,810\tINFO tune.py:1148 -- Total run time: 69.80 seconds (69.28 seconds for the tuning loop).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3731135)\u001b[0m 2025-03-04 14:44:13,917\tWARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3731135)\u001b[0m 2025-03-04 14:44:13,918\tWARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3731135)\u001b[0m 2025-03-04 14:44:13,918\tWARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3731135)\u001b[0m 2025-03-04 14:44:13,918\tWARNING deprecation.py:50 -- DeprecationWarning: `KLCoeffMixin` has been deprecated. This will raise an error in the future!\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3731135)\u001b[0m 2025-03-04 14:44:13,907\tWARNING env.py:162 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3731135)\u001b[0m 2025-03-04 14:44:13,910\tWARNING algorithm_config.py:2558 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final checkpoint saved at: Checkpoint(local_path=/home/jupyter/ray_results/PPO/PPO_CustomMetaEnv-v0_1d2ea_00000_0_2025-03-04_14-44-02/checkpoint_000005)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<ray.tune.tuner.Tuner at 0x7f66e07103a0>,\n",
       " Result(\n",
       "   metrics={'evaluation': {'sampler_results': {'episode_reward_max': 357.0, 'episode_reward_min': 187.0, 'episode_reward_mean': 241.11111111111111, 'episode_len_mean': 241.11111111111111, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [265.0, 197.0, 250.0, 231.0, 252.0, 187.0, 238.0, 193.0, 357.0], 'episode_lengths': [265, 197, 250, 231, 252, 187, 238, 193, 357]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.48735949364785, 'mean_inference_ms': 1.8623420915360585, 'mean_action_processing_ms': 0.1256273612532808, 'mean_env_wait_ms': 0.06141656544650628, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.005308787027994792, 'StateBufferConnector_ms': 0.004564391242133247, 'ViewRequirementAgentConnector_ms': 0.28191407521565753}}, 'episode_reward_max': 357.0, 'episode_reward_min': 187.0, 'episode_reward_mean': 241.11111111111111, 'episode_len_mean': 241.11111111111111, 'episode_media': {}, 'episodes_this_iter': 9, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [265.0, 197.0, 250.0, 231.0, 252.0, 187.0, 238.0, 193.0, 357.0], 'episode_lengths': [265, 197, 250, 231, 252, 187, 238, 193, 357]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.48735949364785, 'mean_inference_ms': 1.8623420915360585, 'mean_action_processing_ms': 0.1256273612532808, 'mean_env_wait_ms': 0.06141656544650628, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.005308787027994792, 'StateBufferConnector_ms': 0.004564391242133247, 'ViewRequirementAgentConnector_ms': 0.28191407521565753}, 'num_agent_steps_sampled_this_iter': 2048, 'num_env_steps_sampled_this_iter': 2048, 'timesteps_this_iter': 2048, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'__all__': {'num_agent_steps_trained': 128.0, 'num_env_steps_trained': 2048.0, 'total_loss': 9.333349190155666}, 'default_policy': {'total_loss': 9.333349190155666, 'policy_loss': -0.012388823643171539, 'vf_loss': 9.343045099576313, 'vf_loss_unclipped': 1613.146400642395, 'vf_explained_var': 0.1606831096112728, 'entropy': 0.5746069621294737, 'mean_kl_loss': 0.008976397897936295, 'curr_lr': 0.0003, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 0.30000001192092896}}, 'num_env_steps_sampled': 10240, 'num_env_steps_trained': 0, 'num_agent_steps_sampled': 10240, 'num_agent_steps_trained': 0}, 'sampler_results': {'episode_reward_max': 402.0, 'episode_reward_min': 12.0, 'episode_reward_mean': 84.29, 'episode_len_mean': 84.29, 'episode_media': {}, 'episodes_this_iter': 12, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [15.0, 29.0, 26.0, 12.0, 52.0, 45.0, 35.0, 21.0, 20.0, 14.0, 56.0, 46.0, 33.0, 13.0, 35.0, 21.0, 15.0, 38.0, 67.0, 43.0, 36.0, 104.0, 44.0, 28.0, 51.0, 30.0, 32.0, 83.0, 37.0, 43.0, 99.0, 80.0, 29.0, 41.0, 82.0, 62.0, 44.0, 42.0, 91.0, 133.0, 22.0, 25.0, 56.0, 32.0, 29.0, 22.0, 68.0, 25.0, 41.0, 40.0, 41.0, 24.0, 27.0, 21.0, 37.0, 64.0, 101.0, 183.0, 63.0, 183.0, 17.0, 122.0, 131.0, 14.0, 62.0, 96.0, 116.0, 15.0, 122.0, 60.0, 20.0, 129.0, 138.0, 97.0, 99.0, 102.0, 181.0, 109.0, 125.0, 79.0, 137.0, 402.0, 147.0, 275.0, 145.0, 158.0, 175.0, 100.0, 150.0, 197.0, 162.0, 103.0, 122.0, 178.0, 159.0, 271.0, 204.0, 210.0, 136.0, 233.0], 'episode_lengths': [15, 29, 26, 12, 52, 45, 35, 21, 20, 14, 56, 46, 33, 13, 35, 21, 15, 38, 67, 43, 36, 104, 44, 28, 51, 30, 32, 83, 37, 43, 99, 80, 29, 41, 82, 62, 44, 42, 91, 133, 22, 25, 56, 32, 29, 22, 68, 25, 41, 40, 41, 24, 27, 21, 37, 64, 101, 183, 63, 183, 17, 122, 131, 14, 62, 96, 116, 15, 122, 60, 20, 129, 138, 97, 99, 102, 181, 109, 125, 79, 137, 402, 147, 275, 145, 158, 175, 100, 150, 197, 162, 103, 122, 178, 159, 271, 204, 210, 136, 233]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5163199346883175, 'mean_inference_ms': 1.8725378445148397, 'mean_action_processing_ms': 0.12607768063929353, 'mean_env_wait_ms': 0.0612330410087649, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.00655055046081543, 'StateBufferConnector_ms': 0.004332065582275391, 'ViewRequirementAgentConnector_ms': 0.28707265853881836}}, 'episode_reward_max': 402.0, 'episode_reward_min': 12.0, 'episode_reward_mean': 84.29, 'episode_len_mean': 84.29, 'episodes_this_iter': 12, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [15.0, 29.0, 26.0, 12.0, 52.0, 45.0, 35.0, 21.0, 20.0, 14.0, 56.0, 46.0, 33.0, 13.0, 35.0, 21.0, 15.0, 38.0, 67.0, 43.0, 36.0, 104.0, 44.0, 28.0, 51.0, 30.0, 32.0, 83.0, 37.0, 43.0, 99.0, 80.0, 29.0, 41.0, 82.0, 62.0, 44.0, 42.0, 91.0, 133.0, 22.0, 25.0, 56.0, 32.0, 29.0, 22.0, 68.0, 25.0, 41.0, 40.0, 41.0, 24.0, 27.0, 21.0, 37.0, 64.0, 101.0, 183.0, 63.0, 183.0, 17.0, 122.0, 131.0, 14.0, 62.0, 96.0, 116.0, 15.0, 122.0, 60.0, 20.0, 129.0, 138.0, 97.0, 99.0, 102.0, 181.0, 109.0, 125.0, 79.0, 137.0, 402.0, 147.0, 275.0, 145.0, 158.0, 175.0, 100.0, 150.0, 197.0, 162.0, 103.0, 122.0, 178.0, 159.0, 271.0, 204.0, 210.0, 136.0, 233.0], 'episode_lengths': [15, 29, 26, 12, 52, 45, 35, 21, 20, 14, 56, 46, 33, 13, 35, 21, 15, 38, 67, 43, 36, 104, 44, 28, 51, 30, 32, 83, 37, 43, 99, 80, 29, 41, 82, 62, 44, 42, 91, 133, 22, 25, 56, 32, 29, 22, 68, 25, 41, 40, 41, 24, 27, 21, 37, 64, 101, 183, 63, 183, 17, 122, 131, 14, 62, 96, 116, 15, 122, 60, 20, 129, 138, 97, 99, 102, 181, 109, 125, 79, 137, 402, 147, 275, 145, 158, 175, 100, 150, 197, 162, 103, 122, 178, 159, 271, 204, 210, 136, 233]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5163199346883175, 'mean_inference_ms': 1.8725378445148397, 'mean_action_processing_ms': 0.12607768063929353, 'mean_env_wait_ms': 0.0612330410087649, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.00655055046081543, 'StateBufferConnector_ms': 0.004332065582275391, 'ViewRequirementAgentConnector_ms': 0.28707265853881836}, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 10240, 'num_agent_steps_trained': 0, 'num_env_steps_sampled': 10240, 'num_env_steps_trained': 0, 'num_env_steps_sampled_this_iter': 2048, 'num_env_steps_trained_this_iter': 0, 'num_env_steps_sampled_throughput_per_sec': 340.34897057916305, 'num_env_steps_trained_throughput_per_sec': 0.0, 'num_steps_trained_this_iter': 0, 'agent_timesteps_total': 10240, 'timers': {'training_iteration_time_ms': 6027.663, 'sample_time_ms': 2651.968, 'synch_weights_time_ms': 3.569}, 'counters': {'num_env_steps_sampled': 10240, 'num_env_steps_trained': 0, 'num_agent_steps_sampled': 10240, 'num_agent_steps_trained': 0}, 'done': True, 'trial_id': '1d2ea_00000', 'perf': {'cpu_util_percent': 23.09375, 'ram_util_percent': 67.51875000000001}, 'experiment_tag': '0'},\n",
       "   path='/home/jupyter/ray_results/PPO/PPO_CustomMetaEnv-v0_1d2ea_00000_0_2025-03-04_14-44-02',\n",
       "   checkpoint=Checkpoint(local_path=/home/jupyter/ray_results/PPO/PPO_CustomMetaEnv-v0_1d2ea_00000_0_2025-03-04_14-44-02/checkpoint_000005)\n",
       " ),\n",
       " Checkpoint(local_path=/home/jupyter/ray_results/PPO/PPO_CustomMetaEnv-v0_1d2ea_00000_0_2025-03-04_14-44-02/checkpoint_000005))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_test(\n",
    "    maml_checkpoint_path=None,        # MAML checkpoint path; if None, PPO trains from scratch.\n",
    "    env_name=\"CustomMetaEnv-v0\",  \n",
    "    env_class=CartPoleMassEnv,              # Optional: custom env class.\n",
    "    env_fn=None,                 # Optional: custom env function.\n",
    "    env_config={},  \n",
    "    total_timesteps=10_000,  \n",
    "    eval_interval=2048,          # Evaluate (and update) every 2048 timesteps.\n",
    "    num_rollout_workers=2,  \n",
    "    framework=\"torch\",\n",
    "    checkpoint_dir=\"ppo_checkpoints/\",\n",
    "    num_samples=1                # Run a single trial instance.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4142192-aaec-4c3c-acf6-46e36c4a3935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e62b27-3ecb-4990-a6e8-52430c78e8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9beea35-b4e3-482d-bb8c-c1a27e792794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985427cd-9db6-490e-ac67-49d559248a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b82141b-d7cd-4aab-b302-6ea4ffd1b588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": ".mamlrayenv",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "TheoRayMaml",
   "language": "python",
   "name": ".mamlrayenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
